{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "(28, 28)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "(x_treino, y_treino), (x_teste, y_teste) = mnist.load_data()\n",
    "\n",
    "# Quantas imagens na base de treino?\n",
    "print(len(x_treino))\n",
    "\n",
    "# Quantas imagens na base de teste?\n",
    "print(len(x_teste))\n",
    "\n",
    "# Qual é o formato de uma imagem?\n",
    "print(x_treino[0].shape)\n",
    "\n",
    "# Como são os dados de uma imagem?\n",
    "print(x_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe5679e6a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "indice = 10000\n",
    "print('label', y_treino[indice])\n",
    "plt.imshow(x_treino[indice], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Preparação dos Dados\n",
    "\n",
    "qtde_elementos_treino = len(x_treino) # Irá retornar 60000\n",
    "qtde_elementos_teste = len(x_teste) # Irá retornar 10000\n",
    "shape = x_treino[0].shape # Shape possui valor (28, 28)\n",
    "tamanho_total = shape[0] * shape[1] # 28 * 28\n",
    "\n",
    "x_treino = x_treino.reshape(qtde_elementos_treino, tamanho_total)\n",
    "x_teste = x_teste.reshape(qtde_elementos_teste, tamanho_total)\n",
    "\n",
    "# Quantos itens temos em x_treino[0]?\n",
    "print(len(x_treino[0]))\n",
    "\n",
    "# O que temos em x_treino[0]?\n",
    "print(x_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Normalização dos dados\n",
    "# Quanto mais próximo de 255 é o valor, mais próximo ele ficará de 1\n",
    "# Ex: 255 será igual a 1\n",
    "# Ex: 127 será igual a 0.49\n",
    "\n",
    "# Garanto que todos os itens da imagem são float32, em vez de int8\n",
    "# Assim conseguimos realizar a divisão para todos os números ao mesmo tempo\n",
    "x_treino = x_treino.astype('float32')\n",
    "x_teste = x_teste.astype('float32')\n",
    "\n",
    "# Normaliza para ficar entre 0 e 1\n",
    "x_treino /= 255\n",
    "x_teste /= 255\n",
    "\n",
    "print(len(x_treino[0]))\n",
    "print(x_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (60000, 784)\n",
      "Teste: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Vamos garantir que ainda temos 60000/10000 samples\n",
    "# e que cada um tem 784 posições\n",
    "\n",
    "print('Treino:', x_treino.shape)\n",
    "print('Teste:', x_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "60000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-944641f3d72a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Quais itens únicos temos em y_treino?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_treino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Quantos itens únicos temos em y_treino?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "# Vamos ajustar o formato de saída (output)\n",
    "\n",
    "# O que temos de valor na label 0 em y_treino[0]?\n",
    "print(y_treino[0])\n",
    "\n",
    "# Queremos transformar para [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "# O que temos em y_treino?\n",
    "print(y_treino)\n",
    "\n",
    "# Quantos itens temos em y_treino?\n",
    "print(len(y_treino))\n",
    "\n",
    "# Quais itens únicos temos em y_treino?\n",
    "print(set(y_treino))\n",
    "\n",
    "# Quantos itens únicos temos em y_treino?\n",
    "qtde_itens_unicos = len(set(y_treino))\n",
    "print(qtde_itens_unicos)\n",
    "\n",
    "# Converte todos itens para informações categóricas\n",
    "y_treino = keras.utils.to_categorical(y_treino, qtde_itens_unicos)\n",
    "y_teste = keras.utils.to_categorical(y_teste, qtde_itens_unicos)\n",
    "\n",
    "# O que temos agora em y_treino[0]?\n",
    "print(y_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 24,380\n",
      "Trainable params: 24,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Criar a rede neural profunda\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(qtde_itens_unicos, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=RMSprop(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2568 - acc: 0.9272 - val_loss: 0.1485 - val_acc: 0.9574\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2535 - acc: 0.9274 - val_loss: 0.1497 - val_acc: 0.9585\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2510 - acc: 0.9287 - val_loss: 0.1560 - val_acc: 0.9574\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.2444 - acc: 0.9308 - val_loss: 0.1514 - val_acc: 0.9592\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2431 - acc: 0.9327 - val_loss: 0.1564 - val_acc: 0.9590\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2436 - acc: 0.9315 - val_loss: 0.1481 - val_acc: 0.9590\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2396 - acc: 0.9316 - val_loss: 0.1490 - val_acc: 0.9587\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2346 - acc: 0.9340 - val_loss: 0.1490 - val_acc: 0.9611\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2391 - acc: 0.9325 - val_loss: 0.1519 - val_acc: 0.9600\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2296 - acc: 0.9349 - val_loss: 0.1560 - val_acc: 0.9582\n"
     ]
    }
   ],
   "source": [
    "# Treina o modelo\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_treino, y_treino,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[[3.0582384e-04 1.3447475e-02 2.7252685e-03 1.7597218e-03 5.8126147e-03\n",
      "  1.5650768e-02 3.0691542e-03 2.2037688e-03 9.5122683e-01 3.7984808e-03]]\n",
      "[8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe57993940>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testando uma entrada qualquer\n",
    "\n",
    "indice = 998\n",
    "\n",
    "print(y_teste[indice])\n",
    "\n",
    "imagem = x_teste[indice].reshape((1,784))\n",
    "#print(len(x_teste[indice]))\n",
    "#print(len(imagem))\n",
    "#print(x_teste[indice])\n",
    "#print(imagem)\n",
    "\n",
    "prediction = model.predict(imagem)\n",
    "print(prediction)\n",
    "\n",
    "prediction_class = model.predict_classes(imagem)\n",
    "print(prediction_class)\n",
    "\n",
    "(x_treino_img, y_treino_img), (x_teste_img, y_teste_img) = mnist.load_data()\n",
    "plt.imshow(x_teste_img[indice], cmap=plt.cm.binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
